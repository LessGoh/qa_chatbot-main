{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "xm7jCuQ_4LOj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Retrieval-Augmented Generation (RAG) Model for QA Bot Using Pinecone and OpenAI**"
      ],
      "metadata": {
        "id": "whVreF0L4Ng8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import getpass\n",
        "os.environ[\"PINECONE_API_KEY\"] = getpass.getpass()\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass()"
      ],
      "metadata": {
        "id": "n3-oZxEQ4D7o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Pipeline Demonstration: Data Loading to Question Answering**:\n",
        "\n",
        "  We start by installing the necessary libraries. These include tools for document loading, text splitting, embeddings generation, and integration with Pinecone and OpenAI."
      ],
      "metadata": {
        "id": "Ook9t85m6Ygv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "mNi-6yZpyEtL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e1028db-b190-450a-b5f6-68f8153e834b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain_community in /usr/local/lib/python3.10/dist-packages (0.3.0)\n",
            "Requirement already satisfied: langchain_pinecone in /usr/local/lib/python3.10/dist-packages (0.2.0)\n",
            "Requirement already satisfied: langchain_openai in /usr/local/lib/python3.10/dist-packages (0.2.0)\n",
            "Requirement already satisfied: unstructured in /usr/local/lib/python3.10/dist-packages (0.15.13)\n",
            "Requirement already satisfied: langchain-text-splitters in /usr/local/lib/python3.10/dist-packages (0.3.0)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.3.0)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.0.35)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (3.9.5)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.6.7)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.3.5)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.112 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.1.125)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (1.26.4)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.5.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (8.5.0)\n",
            "Requirement already satisfied: pinecone-client<6.0.0,>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain_pinecone) (5.0.1)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.40.0 in /usr/local/lib/python3.10/dist-packages (from langchain_openai) (1.47.0)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.10/dist-packages (from langchain_openai) (0.7.0)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.10/dist-packages (from unstructured) (5.2.0)\n",
            "Requirement already satisfied: filetype in /usr/local/lib/python3.10/dist-packages (from unstructured) (1.2.0)\n",
            "Requirement already satisfied: python-magic in /usr/local/lib/python3.10/dist-packages (from unstructured) (0.4.27)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from unstructured) (4.9.4)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from unstructured) (3.8.1)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from unstructured) (0.9.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from unstructured) (4.12.3)\n",
            "Requirement already satisfied: emoji in /usr/local/lib/python3.10/dist-packages (from unstructured) (2.13.0)\n",
            "Requirement already satisfied: python-iso639 in /usr/local/lib/python3.10/dist-packages (from unstructured) (2024.4.27)\n",
            "Requirement already satisfied: langdetect in /usr/local/lib/python3.10/dist-packages (from unstructured) (1.0.9)\n",
            "Requirement already satisfied: rapidfuzz in /usr/local/lib/python3.10/dist-packages (from unstructured) (3.9.7)\n",
            "Requirement already satisfied: backoff in /usr/local/lib/python3.10/dist-packages (from unstructured) (2.2.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from unstructured) (4.12.2)\n",
            "Requirement already satisfied: unstructured-client in /usr/local/lib/python3.10/dist-packages (from unstructured) (0.25.9)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from unstructured) (1.16.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from unstructured) (4.66.5)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from unstructured) (5.9.5)\n",
            "Requirement already satisfied: python-oxmsg in /usr/local/lib/python3.10/dist-packages (from unstructured) (0.0.1)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.9.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.11.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.22.0)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.0->langchain_community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.0->langchain_community) (24.1)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.112->langchain_community) (0.27.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.112->langchain_community) (3.10.7)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.40.0->langchain_openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.40.0->langchain_openai) (1.7.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.40.0->langchain_openai) (0.5.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.40.0->langchain_openai) (1.3.1)\n",
            "Requirement already satisfied: certifi>=2019.11.17 in /usr/local/lib/python3.10/dist-packages (from pinecone-client<6.0.0,>=5.0.0->langchain_pinecone) (2024.8.30)\n",
            "Requirement already satisfied: pinecone-plugin-inference<2.0.0,>=1.0.3 in /usr/local/lib/python3.10/dist-packages (from pinecone-client<6.0.0,>=5.0.0->langchain_pinecone) (1.1.0)\n",
            "Requirement already satisfied: pinecone-plugin-interface<0.0.8,>=0.0.7 in /usr/local/lib/python3.10/dist-packages (from pinecone-client<6.0.0,>=5.0.0->langchain_pinecone) (0.0.7)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from pinecone-client<6.0.0,>=5.0.0->langchain_pinecone) (2.0.7)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.23.4)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.10)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.1.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.9.11)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->unstructured) (2.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from langdetect->unstructured) (1.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured) (1.4.2)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.10/dist-packages (from python-oxmsg->unstructured) (0.47)\n",
            "Requirement already satisfied: cryptography>=3.1 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured) (43.0.1)\n",
            "Requirement already satisfied: deepdiff>=6.0 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured) (8.0.1)\n",
            "Requirement already satisfied: jsonpath-python>=1.0.6 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured) (1.0.6)\n",
            "Requirement already satisfied: mypy-extensions>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured) (1.0.0)\n",
            "Requirement already satisfied: nest-asyncio>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured) (1.6.0)\n",
            "Requirement already satisfied: pypdf>=4.0 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured) (5.0.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured) (2.8.2)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured) (1.0.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.40.0->langchain_openai) (1.2.2)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=3.1->unstructured-client->unstructured) (1.17.1)\n",
            "Requirement already satisfied: orderly-set==5.2.2 in /usr/local/lib/python3.10/dist-packages (from deepdiff>=6.0->unstructured-client->unstructured) (5.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.112->langchain_community) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.112->langchain_community) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.0->langchain_community) (3.0.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=3.1->unstructured-client->unstructured) (2.22)\n"
          ]
        }
      ],
      "source": [
        "# Library installation\n",
        "!pip install \\\n",
        "  langchain_community \\\n",
        "  langchain_pinecone \\\n",
        "  langchain_openai \\\n",
        "  unstructured \\\n",
        "  langchain-text-splitters \\\n",
        "  langchain\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "UHtdgrVPyW5L"
      },
      "outputs": [],
      "source": [
        "from langchain_pinecone import PineconeVectorStore\n",
        "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "import os\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loading the Document:**\n",
        "\n",
        "  We mount Google Drive to access the PDF file and load the document using PyPDFLoader. This loader breaks down the PDF into multiple pages, preparing them for embedding generation"
      ],
      "metadata": {
        "id": "3RBv_CtK62eC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Bd3OVLYxbtW",
        "outputId": "ea18fbe1-29f9-4030-e427-fd622f943f6f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lPbx4EC3q1rE"
      },
      "source": [
        "**PDF** file loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Rr7aNkcAyq4L"
      },
      "outputs": [],
      "source": [
        "#with open('iesc111.pdf','r') as file:\n",
        "location = '/content/drive/My Drive/iesc111.pdf'\n",
        "pdf_loader = PyPDFLoader(location)\n",
        "\n",
        "pages = pdf_loader.load_and_split()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Splitting the Document into Chunks:**\n",
        "\n",
        "  To ensure optimal embeddings, the document is split into smaller chunks. Here, we use the RecursiveCharacterTextSplitter, which divides the content into smaller parts with overlap to preserve context."
      ],
      "metadata": {
        "id": "1m4d6Qv37vP9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load and split on characters\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
        "splits = text_splitter.split_documents(pages)"
      ],
      "metadata": {
        "id": "U6lPo6eB79va"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "rxv1r_Mty9mD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b3ad1b6-d7d0-43b0-9fca-e0448479a30d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(metadata={'source': '/content/drive/My Drive/iesc111.pdf', 'page': 0}, page_content='Everyday we hear sounds from various\\nsources like humans, bir ds, bells, machines,\\nvehicles, televisions, radios etc. Sound is a\\nform of ener gy which pr oduces a sensation\\nof hearing in our ears. Ther e are also other\\nforms of energy like mechanical energy, light\\nenergy, etc. W e have talked about mechanical\\nenergy in the pr evious chapters. Y ou have\\nbeen taught about conservation of energy,\\nwhich states that we can neither create nor\\ndestr oy ener gy. W e  can just change it fr om\\none for m to another . When you clap, a sound\\nis produced. Can you produce sound without\\nutilising your energy? Which form of energy\\ndid you use to produce sound? In this\\nchapter we are going to learn how sound is\\nproduced and how it is transmitted through\\na medium and received by our ears.\\n11.1 Production of Sound\\nActivity _____________ 11.1\\n•Take a tuning fork and set it vibrating\\nby striking its pr ong on a rubber pad.\\nBring it near your ear .\\n•Do you hear any sound?')"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "splits[0]"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sf3OlCxc76JL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "nK3Cu4nBzGk5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hxr2yI5uq1rG"
      },
      "source": [
        "# # Vectore Store Initialization\n",
        "\n",
        "**Embeddings Generation and Vector Store Initialization:**\n",
        "\n",
        "  Using the OpenAI model, we generate document embeddings. These embeddings are stored in Pinecone's vector database for efficient similarity search."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Py-QrLYe2TLJ"
      },
      "outputs": [],
      "source": [
        "# Define embeddings and index for vectorestore\n",
        "embeddings = OpenAIEmbeddings()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "R273j5s_20cq"
      },
      "outputs": [],
      "source": [
        "use_serverless = True"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install protoc-gen-openapiv2\n",
        "# Install the missing 'protoc-gen-openapiv2' module.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7LpMRJgo0bmi",
        "outputId": "d2dc926b-97e8-447a-97ee-2762231e4b5d"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: protoc-gen-openapiv2 in /usr/local/lib/python3.10/dist-packages (0.0.1)\n",
            "Requirement already satisfied: googleapis-common-protos in /usr/local/lib/python3.10/dist-packages (from protoc-gen-openapiv2) (1.65.0)\n",
            "Requirement already satisfied: protobuf>=4.21.0 in /usr/local/lib/python3.10/dist-packages (from protoc-gen-openapiv2) (5.28.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Configuring Pinecone Vector Store:**\n",
        "\n",
        "We initialize and configure a Pinecone vector store to hold our document embeddings. The index is created with a dimensionality of 1536, matching the embedding dimensions.\n",
        "\n",
        "**from pinecone.grpc import PineconeGRPC as Pinecone\n",
        "index_name = \"sarvam-chat\"\n",
        "pc = Pinecone()\n",
        "pc.create_index(index_name, dimension=1536, metric='cosine')\n",
        "index = pc.Index(index_name) **\n",
        "\n"
      ],
      "metadata": {
        "id": "69e0U_kl86y3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "xHUEMgnlq1rH"
      },
      "outputs": [],
      "source": [
        "from pinecone.grpc import PineconeGRPC as Pinecone\n",
        "from pinecone import ServerlessSpec, PodSpec\n",
        "import time\n",
        "# configure client\n",
        "pc = Pinecone()\n",
        "if use_serverless:\n",
        "    spec = ServerlessSpec(cloud='aws', region='us-east-1')\n",
        "else:\n",
        "    # if not using a starter index, you should specify a pod_type too\n",
        "    spec = PodSpec()\n",
        "# check for and delete index if already exists\n",
        "index_name = \"sarvam-chat\"\n",
        "items = pc.list_indexes().indexes\n",
        "existing_indexes = [item['name'] for item in items]\n",
        "if index_name in existing_indexes:\n",
        "    pc.delete_index(index_name)\n",
        "# create a new index\n",
        "pc.create_index(\n",
        "    index_name,\n",
        "    dimension=1536,  # dimensionality of text-embedding-ada-002\n",
        "    metric='cosine',\n",
        "    spec=spec\n",
        ")\n",
        "# wait for index to be initialized\n",
        "while not pc.describe_index(index_name).status['ready']:\n",
        "    time.sleep(1)\n"
      ]
    },
    {
      "source": [
        "!pip install protoc-gen-openapiv2\n",
        "# Install the missing 'protoc-gen-openapiv2' module."
      ],
      "cell_type": "code",
      "metadata": {
        "id": "ucf6GQm-Ao2K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3ef4a7c-e3aa-4126-b4a8-fd17fc30cffe"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: protoc-gen-openapiv2 in /usr/local/lib/python3.10/dist-packages (0.0.1)\n",
            "Requirement already satisfied: googleapis-common-protos in /usr/local/lib/python3.10/dist-packages (from protoc-gen-openapiv2) (1.65.0)\n",
            "Requirement already satisfied: protobuf>=4.21.0 in /usr/local/lib/python3.10/dist-packages (from protoc-gen-openapiv2) (5.28.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_HX_9GmYq1rH",
        "outputId": "898e2f02-c17e-43c3-b57f-e53696ef0f21"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'dimension': 1536,\n",
              " 'index_fullness': 0.0,\n",
              " 'namespaces': {'': {'vector_count': 0}},\n",
              " 'total_vector_count': 0}"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "index = pc.Index(index_name)\n",
        "index.describe_index_stats()\n",
        "\n",
        "# Response:\n",
        "# {'dimension': 1536,\n",
        "# 'index_fullness': 0.0,\n",
        "# 'namespaces': {},\n",
        "# 'total_vector_count': 0}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Adding Documents to the Vector Store:**\n",
        "\n",
        "The split document chunks are stored in Pinecone's vector store to prepare for efficient retrieval."
      ],
      "metadata": {
        "id": "PCof2Sgw9xhR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "owj6y4N5q1rH"
      },
      "outputs": [],
      "source": [
        "from langchain_pinecone import PineconeVectorStore\n",
        "text_field = \"text\"\n",
        "vectorstore = PineconeVectorStore(\n",
        "    index, embeddings, text_field\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uw6LwP9dq1rH",
        "outputId": "177b51d6-2ab1-4ba1-abbd-1e59338b3cc3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['222acefc-910b-4e24-bc34-db2126e4d8de',\n",
              " '0c84250d-d266-4b14-8dd2-c4508c6248d7',\n",
              " 'ecd1766f-b557-459e-b166-be6e13b01204',\n",
              " 'c13c4e7b-b4fb-428f-838b-e9c0b5b7b6a1',\n",
              " 'a9bc041c-5c95-4a0f-8413-093c13028b43',\n",
              " 'b8e1708c-d958-4892-ac77-ac1f79e4b498',\n",
              " 'dbc8a4ea-ec22-4849-a835-3023eaffd8ce',\n",
              " 'b9ad3ceb-92ea-417f-90c7-005319f25ad2',\n",
              " '060b9eaf-8581-4251-b592-cc44a4d1289c',\n",
              " '5e5e714d-53ef-44b1-b7b3-7b51366e613c',\n",
              " '742fda1b-811d-4124-9fc7-8fef66ef4f67',\n",
              " 'd651a772-1bd0-4108-904d-c48cff9844f8',\n",
              " 'c7c123e9-bfb3-4e85-b047-e7eb85f5d884',\n",
              " '3c662703-7763-4b62-b303-5847cbd17898']"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "# async_req is required to make sure it is updated in real time\n",
        "vectorstore.add_documents(documents= pages, async_req=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Testing Document Similarity Search:**\n",
        "\n",
        "We test the system by performing a similarity search. Given a user query, we retrieve the most relevant document chunks from the vector store."
      ],
      "metadata": {
        "id": "lutNrjBt-Cou"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "x7SHlfD43fN0"
      },
      "outputs": [],
      "source": [
        "# Testing the similarity search\n",
        "query = \"What is the book about?\"\n",
        "similar_docs = vectorstore.similarity_search(query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "3NtGloln3tq5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "145b3368-30ab-4fec-8a89-91dcb6982ced"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "similar_docs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "DyIvTZOwq1rI"
      },
      "outputs": [],
      "source": [
        "def format_docs(docs):\n",
        "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "** Generating Answers with Retrieval-Augmented Generation (RAG):**\n",
        "\n",
        "We use a combination of retrieval and language model generation to answer user questions. The relevant document chunks are retrieved from Pinecone and passed as context to a generative language model (ChatGPT) to create answers."
      ],
      "metadata": {
        "id": "duB9pNdm-jwz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "cwrZ6IjC-j_N"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "JMb9Wibdq1rI"
      },
      "outputs": [],
      "source": [
        "# Using LCEL chains to QA\n",
        "question = \"What is the book about?\"\n",
        "retriever = vectorstore.as_retriever()\n",
        "prompt_rag = (\n",
        "    PromptTemplate.from_template(\"Generate answers for given question: {question} based on the context {context}. In generated response provide reference to metadata from which context used in generating response\")\n",
        ")\n",
        "llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)\n",
        "\n",
        "rag_chain = (\n",
        "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
        "    | prompt_rag\n",
        "    | llm\n",
        ")\n",
        "\n",
        "res = rag_chain.invoke(question)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VbdcEvOwq1rI",
        "outputId": "66f62429-6fb4-4422-a7fc-7e989f6159d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The book appears to be a comprehensive educational resource focused on the science of sound, covering various fundamental concepts related to acoustics. It discusses the nature of sound waves, including their speed, frequency, wavelength, and the physiological aspects of how sound is perceived, such as loudness and pitch. The text also delves into practical applications of sound, such as the use of ultrasound in cleaning and detecting defects in materials, as well as the principles of sound propagation and reflection.\n",
            "\n",
            "Key topics include:\n",
            "\n",
            "1. **Sound Wave Properties**: The book explains how sound waves travel through different media, the relationship between frequency and pitch, and how amplitude affects loudness. It also provides mathematical relationships, such as the calculation of frequency based on speed and wavelength.\n",
            "\n",
            "2. **Audibility and Sound Characteristics**: It defines the audible range for humans and distinguishes between infrasonic and ultrasonic sounds, emphasizing the physiological response of the ear to sound intensity.\n",
            "\n",
            "3. **Applications of Sound**: The text highlights the practical uses of sound in various fields, including medical imaging and industrial testing, showcasing the versatility of sound waves beyond mere auditory experiences.\n",
            "\n",
            "4. **Historical Context**: The book includes a brief biography of Heinrich Rudolph Hertz, detailing his contributions to the field of electromagnetism and sound, and how his work laid the groundwork for modern communication technologies.\n",
            "\n",
            "5. **Sound Phenomena**: Concepts such as reverberation, echo, and the effects of temperature on sound propagation are discussed, providing a deeper understanding of how sound interacts with the environment.\n",
            "\n",
            "Overall, the book serves as an educational tool for students and anyone interested in the science of sound, offering both theoretical knowledge and practical insights into the behavior and applications of sound waves.\n",
            "\n",
            "**Reference Metadata**: The context for this response is derived from the provided text on sound, which includes definitions, properties, applications, and historical contributions related to sound science (SOUND 13913, SCIENCE 130, SCIENCE 138, SOUND 131).\n"
          ]
        }
      ],
      "source": [
        "print(res.content)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"What are the characteristics of a sound wave?\"\n",
        "retriever = vectorstore.as_retriever()\n",
        "prompt_rag = (\n",
        "    PromptTemplate.from_template(\"Generate answers for given question: {question} based on the context {context}. In generated response provide reference to metadata from which context used in generating response\")\n",
        ")\n",
        "llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)\n",
        "\n",
        "rag_chain = (\n",
        "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
        "    | prompt_rag\n",
        "    | llm\n",
        ")\n",
        "\n",
        "res = rag_chain.invoke(question)"
      ],
      "metadata": {
        "id": "vedaxWZgBdX5"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(res.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Tcnko7yCwMV",
        "outputId": "2398d36e-030b-4eb3-8f9f-61357545f900"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The characteristics of a sound wave can be summarized as follows:\n",
            "\n",
            "1. **Nature of Sound**: Sound is produced by the vibration of different objects, creating disturbances in a medium (solid, liquid, or gas).\n",
            "\n",
            "2. **Wave Type**: Sound travels as a longitudinal wave, meaning that the oscillations of the particles in the medium occur parallel to the direction of wave propagation. This results in regions of compression (high pressure) and rarefaction (low pressure) as the wave moves through the medium.\n",
            "\n",
            "3. **Energy Propagation**: In sound propagation, it is the energy of the sound that travels through the medium, not the particles themselves. The particles oscillate around their equilibrium positions but do not move along with the wave.\n",
            "\n",
            "4. **Wavelength and Frequency**: The distance between two consecutive compressions or rarefactions is called the wavelength (λ). The time taken for one complete oscillation is the time period (T), and the number of oscillations per unit time is the frequency (ν). These properties are related by the equation \\( v = λν \\), where \\( v \\) is the speed of sound.\n",
            "\n",
            "5. **Speed of Sound**: The speed of sound depends on the nature and temperature of the medium through which it travels. Generally, sound travels faster in solids than in liquids and faster in liquids than in gases.\n",
            "\n",
            "6. **Reflection of Sound**: Sound waves obey the law of reflection, where the angle of incidence equals the angle of reflection. This principle is crucial for understanding phenomena like echoes.\n",
            "\n",
            "7. **Hearing Range**: The audible range for humans is typically between 20 Hz and 20 kHz. Frequencies below this range are termed infrasonic, while those above are called ultrasonic.\n",
            "\n",
            "8. **Intensity and Loudness**: The intensity of sound is defined as the amount of sound energy passing through a unit area per second. Loudness is a physiological response of the ear to the intensity of sound, which can vary even for sounds of equal intensity due to factors like frequency and the ear's sensitivity.\n",
            "\n",
            "9. **Quality of Sound**: The quality or timbre of sound allows us to distinguish between different sounds, even if they have the same pitch and loudness. This characteristic is influenced by the mixture of frequencies present in the sound.\n",
            "\n",
            "10. **Applications**: Sound waves have various applications, including medical imaging (ultrasonography), industrial uses, and in technologies that utilize the reflection of sound waves.\n",
            "\n",
            "These characteristics highlight the complex nature of sound waves and their behavior in different media, as well as their significance in various practical applications.\n",
            "\n",
            "*Reference: The information provided is based on the context from the educational material on sound waves, including their properties, behavior, and applications as outlined in the provided text.*\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "**Model Architecture:**\n",
        "\n",
        "The architecture is designed around two primary components:\n",
        "\n",
        "**Vector Store (Retrieval)**\n",
        "\n",
        "**Document Loader:** Loads the document in the form of pages.\n",
        "\n",
        "**Text Splitter:** Splits the document into smaller chunks (e.g., 1000 characters per chunk with overlap).\n",
        "Embeddings Generation: Using OpenAI, document embeddings are generated. These embeddings represent the content in high-dimensional space.\n",
        "Pinecone Vector Store: The document chunks and their embeddings are stored in Pinecone for efficient retrieval based on semantic similarity.\n",
        "\n",
        "**Generative Model (Answer Generation):**\n",
        "\n",
        "**Retriever:** Fetches the top-k most relevant document chunks from Pinecone based on the user query.\n",
        "\n",
        "**Language Model (ChatGPT):** Receives the retrieved context and generates a coherent answer to the query using RAG.\n",
        "\n",
        "**Prompt Template:** A structured prompt is created using a template that combines the query and the retrieved context, guiding the generative model.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "z6yO6g6M--jI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "**Retrieval Approach:**\n",
        "The system follows a retrieval-augmented approach:\n",
        "\n",
        "**Document Retrieval:** When a query is submitted, the system searches the vector store for the most relevant chunks using a similarity search (cosine similarity). This ensures that only the most pertinent parts of the document are considered for answering.\n",
        "**Context and Question Prompting:** The retrieved chunks are then passed as context to the generative language model, which answers the query based on both the retrieved context and the query itself.\n",
        "\n",
        "\n",
        "**Generative Response Creation**\n",
        "The generative responses are created using the following process:\n",
        "\n",
        "**Contextual Answering:** The retrieved document chunks act as the basis for the language model to answer the user's question. This ensures that the generated responses are not hallucinations but are grounded in the content of the document.\n",
        "**Metadata Inclusion:** The prompt template ensures that the response contains references to the source of the information used, providing transparency and credibility.\n",
        "\n",
        "**Example Queries and Outputs**\n",
        "Here are a few examples of the system's queries and responses:\n",
        "\n",
        "Query 1: \"What is the book about?\" Answer: \"The book is a comprehensive guide on the subject of XYZ, covering topics such as... \"\n",
        "\n",
        "Query 2: \"Explain the key concept.\" Answer: \" it introduces the core concept of ABC, where...\"\n",
        "\n"
      ],
      "metadata": {
        "id": "bn48sBGVMaNO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "zW1pmH4EMazp"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "br5qqnBMC1wI"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.15 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    },
    "vscode": {
      "interpreter": {
        "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}